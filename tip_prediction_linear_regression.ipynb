{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tip Prediction with PySpark using Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll walk through using PySpark to solve a regression problem. Specifically, we'll develop a linear model to estimate tip values based on features that are continuous, categorical, and string-based.\n",
    "\n",
    "This project will be utilizing Spark's ML library, which is designed to be used with DataFrame structures and utilizes pipelines to make things efficient and concise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some stuff first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorSlicer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#the following lines allow the notebook to have multiple outputs for a single cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the data. Note that I'm using PySpark with the databricks package to load csv data directly to a DataFrame. You should load the notebook with the following command:  \n",
    "PYSPARK_DRIVER_PYTHON=ipython PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" $SPARK_HOME/bin/pyspark --packages com.databricks:spark-csv_2.10:1.3.0  \n",
    "\n",
    "We'll also split the data into test/train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>label</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  label     sex smoker  day    time  size\n",
       "0       16.99   1.01  Female     No  Sun  Dinner   2.0\n",
       "1       10.34   1.66    Male     No  Sun  Dinner   3.0\n",
       "2       21.01   3.50    Male     No  Sun  Dinner   3.0\n",
       "3       23.68   3.31    Male     No  Sun  Dinner   2.0\n",
       "4       24.59   3.61  Female     No  Sun  Dinner   4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data as dataframe\n",
    "data = sqlContext.read.load('tips.csv', format='com.databricks.spark.csv', header='true', inferSchema='true')\n",
    "\n",
    "#display the structure\n",
    "data.printSchema()\n",
    "\n",
    "#the column \"tip\" is the output, so rename it to \"label\"\n",
    "#this is the default name for the label column for the linear regression model\n",
    "#so i'll just stick with naming conventions here\n",
    "data = data.withColumnRenamed('tip', 'label')\n",
    "\n",
    "#note that the \"size\" column is of type integer. change this to double to avoid\n",
    "#weird results later on\n",
    "data = data.withColumn('size', data['size'].cast(DoubleType()))\n",
    "data.printSchema()\n",
    "                   \n",
    "#randomly split the data into a test/train set and validation set (80%/20%)\n",
    "splits = data.randomSplit([0.8, 0.2])\n",
    "data_train = splits[0]\n",
    "data_val = splits[1]\n",
    "\n",
    "#take a look at some data\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to deal with our string and categorical features. Use StringIndexer to convert string-based categorical features to a numeric form, and use OneHotEncoder to convert numeric-based categorical features to one-hot encoded values. Note that we only have to do one-hot encoding for cases when the categorical feature has more than two possible states. Otherwise just doing a stringIndexer is good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#convert sex --> sex_numeric. no one-hot encoding required because this can only have \n",
    "#two values (male or female)\n",
    "stringIndexerSex = StringIndexer(inputCol='sex', outputCol='sex_numeric')\n",
    "\n",
    "#convert smoker --> smoker_numeric. again, no one-hot encoding required because this can \n",
    "#only have two values (yes or no)\n",
    "stringIndexerSmoker = StringIndexer(inputCol='smoker', outputCol='smoker_numeric')\n",
    "\n",
    "#convert day --> day_numeric. also do one-hot encoding because there are mulitple possible values for day\n",
    "#ie, monday gets mapped to the integer 0, and tuesday=1, wed=2, etc.\n",
    "#then do one-hot encoding\n",
    "stringIndexerDay = StringIndexer(inputCol='day', outputCol='day_numeric')\n",
    "encoderDay = OneHotEncoder(inputCol='day_numeric', outputCol='day_vector')\n",
    "\n",
    "#convert time --> time_numeric. no one-hot encoding required because this can only have \n",
    "#two values (lunch or dinner)\n",
    "stringIndexerTime = StringIndexer(inputCol='time', outputCol='time_numeric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining variables \"total_bill\" and \"size\" are continuous variables. Well, kind of...one could argue that \"size\" is a categorical value. But I'll be treating it as continuous, because spark gave better results with \"size\" as continuous rather than categorical. We need to normalize both features to mean=0, standard deviation=1 before training the linear regression model. Conveniently, there is a function to do that using spark. First, combine all continuous variables into a single vector using VectorAssembler. Then pass to StandardScaler to do column-wise normalization (the output will be another vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assemblerScaler = VectorAssembler(inputCols=['size', 'total_bill'], outputCol='cont_feats')\n",
    "scaler = StandardScaler(inputCol='cont_feats', outputCol='cont_feats_scaled', withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly combine all the features (both one-hot encoded features and continuous, normalized features) into one big vector for input to the linear regression model. Call this vector \"features\", as the default name for the features vector for linear regression is \"features\". Again, we'll stick with the naming conventions to keep things more clear.  \n",
    "\n",
    "Note that there are eight features in total. Gender, smoking preference, and time are all categorical variables with two possible values, and so they each are represented by a single column. Day is categorical variable with 4 possible values, so one-hot encoding results in 3 possible values. There are also two continuous features, size and total bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_feats = ['sex_numeric', 'smoker_numeric', 'day_vector', 'time_numeric', 'cont_feats_scaled']\n",
    "assemblerAllFeatures = VectorAssembler(inputCols=all_feats, outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can conveniently put all the above steps together into a pipeline for intput into the linear regression model! For now, lets test the pipeline to see that the output is what we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>label</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>sex_numeric</th>\n",
       "      <th>smoker_numeric</th>\n",
       "      <th>day_numeric</th>\n",
       "      <th>day_vector</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>cont_feats</th>\n",
       "      <th>cont_feats_scaled</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 3.07]</td>\n",
       "      <td>[-1.62069996297, -1.88705084441]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, -1.62069996297,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 5.75]</td>\n",
       "      <td>[-0.54207712072, -1.57079345366]</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -0.54207712072,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 7.25]</td>\n",
       "      <td>[-1.62069996297, -1.39378372003]</td>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 0.0, -1.62069996297,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  label     sex smoker  day    time  size  sex_numeric  \\\n",
       "0        3.07    1.0  Female    Yes  Sat  Dinner   1.0          1.0   \n",
       "1        5.75    1.0  Female    Yes  Fri  Dinner   2.0          1.0   \n",
       "2        7.25    1.0  Female     No  Sat  Dinner   1.0          1.0   \n",
       "\n",
       "   smoker_numeric  day_numeric       day_vector  time_numeric   cont_feats  \\\n",
       "0             1.0          0.0  (1.0, 0.0, 0.0)           0.0  [1.0, 3.07]   \n",
       "1             1.0          3.0  (0.0, 0.0, 0.0)           0.0  [2.0, 5.75]   \n",
       "2             0.0          0.0  (1.0, 0.0, 0.0)           0.0  [1.0, 7.25]   \n",
       "\n",
       "                  cont_feats_scaled  \\\n",
       "0  [-1.62069996297, -1.88705084441]   \n",
       "1  [-0.54207712072, -1.57079345366]   \n",
       "2  [-1.62069996297, -1.39378372003]   \n",
       "\n",
       "                                            features  \n",
       "0  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, -1.62069996297,...  \n",
       "1  (1.0, 1.0, 0.0, 0.0, 0.0, 0.0, -0.54207712072,...  \n",
       "2  (1.0, 0.0, 1.0, 0.0, 0.0, 0.0, -1.62069996297,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the pipeline\n",
    "pipeline = Pipeline(stages=[stringIndexerSex, stringIndexerSmoker, stringIndexerDay, encoderDay, \\\n",
    "                            stringIndexerTime, assemblerScaler, scaler, assemblerAllFeatures])\n",
    "#fit the pipeline on the training data. what it means to \"fit\" the pipeline is to basically go through each of the \n",
    "#stages of the piepline and figure out the appropriate parameters. for example, in the stringIndexerSex stage, it \n",
    "#may decide to define Female=1 and Male=0 (or vice versa)\n",
    "pipelineModel = pipeline.fit(data_train)\n",
    "\n",
    "#actually transform the data now that the pipeline is fit. note that the resultant features vector may be sparse\n",
    "output = pipelineModel.transform(data_train)\n",
    "\n",
    "#take a look at the output\n",
    "output.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally a good idea to take a look at the correlations between input features. This is a good first step at feature selection, in which we can remove any highly correlated (and therefore redundant) features. Correlation analysis can only be done with continuous variables, of which we only have two (total bill and size).\n",
    "\n",
    "The only tricky part of this section is extracting out the two continuous features from the features vector. To do so, define the function \"dosplit\" that will take each features vector, convert it to a list, grab the last two values of the list, and then return them as two columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preview of continuous features DF:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_scaled</th>\n",
       "      <th>total_bill_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.620700</td>\n",
       "      <td>-1.887051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.542077</td>\n",
       "      <td>-1.570793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.620700</td>\n",
       "      <td>-1.393784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size_scaled  total_bill_scaled\n",
       "0    -1.620700          -1.887051\n",
       "1    -0.542077          -1.570793\n",
       "2    -1.620700          -1.393784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_scaled</th>\n",
       "      <th>total_bill_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>size_scaled</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.556958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bill_scaled</th>\n",
       "      <td>0.556958</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   size_scaled  total_bill_scaled\n",
       "size_scaled           1.000000           0.556958\n",
       "total_bill_scaled     0.556958           1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e8e5f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAIHCAYAAACoiZn9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmUbHdVL/BvXRKIkDBokFEFQbbgkzGGBMIgEEGQGZRZ\ngoGE58BCkFkFgYfyABVdAcIKAoIgKvEJ+AIKMiQhjA8MQ7ZE4KEMAkES4GUgt/v9UXWlc8ntW0nl\n3NPp8/msVau76nTV2XVXurPre/b5ndn6+noAABjGjrELAADYzjRbAAAD0mwBAAxIswUAMCDNFgDA\ngDRbAAAD2m/IF//MEXe3rgRsI4+9273HLgG4jL372b82G2vfQ/cJP3Hy20d7bxtJtgAABjRosgUA\nsEezaWQ+03iXAAAjkWwBAOOYbYmRqsFJtgAABiTZAgBGMdsh2QIAYEWSLQBgHM5GBABgVZItAGAc\nzkYEAGBVki0AYBwTORtRswUAjGLmMCIAAKuSbAEA49gxjcxnGu8SAGAkki0AYBxmtgAAWJVkCwAY\nh2QLAIBVSbYAgFHMnI0IAMCqJFsAwDgkWwAArEqyBQCMw9mIAACsSrIFAIxiJtkCAGBVki0AYBw7\nJFsAAKxIsgUAjGM2jcxnGu8SAGAkki0AYBwTmdnSbAEAo7D0AwAAK5NsAQDjMCAPAMCqJFsAwDgm\nMiAv2QIAGJBkCwAYxWzHNDIfzRYAMElVtSPJcUlukeT8JEd395kbtj8yyW8lOTvJq7v7hMXjT09y\nnyRXTHLcrsf3RLMFAIxj/HW27pfkgO4+vKoOS/LiJPdNkqo6OMlzk9w6yTeT/GNVvTPJDZLcLsnt\nk1w5yZP3tpNp5HcAAN/viCQnJUl3n5bkkA3bfjzJx7v7G929luRDSQ5Lcvckpyc5Mclbkrx1bzvR\nbAEA45jNhr3t3VUzP0S4y86q2nXU7zNJfqqqrlVVV05y1yRXSXJw5k3Zg5Mcm+T1VbXpzjRbAMBU\nnZPkoA33d3T3hUnS3f+Z5IlJ/ibJG5J8NMnXk5yV5O3dfUF3d5Lzklxzs52Y2QIAxjH+2YinJLl3\nkjctZrZO37VhkXDdOskdMh+E/4ckz0iyM8kTquolSa6Tedp11mY70WwBAFN1YpIjq+rUJLMkR1XV\nw5Ic2N3HV1UyT7TOS/Li7v56krdW1R2TfDDzI4S/2t07N9uJZgsAGMVs5LMRF4Pvx+728Bkbtj8n\nyXMu5nlPuST7GT2/AwDYziRbAMA4XBsRAIBVSbYAgHHMppH5TONdAgCMRLIFAIxj/Gsj7hOaLQBg\nFDMD8gAArEqyBQCMYyKHESVbAAADkmwBAOMY/0LU+8Q03iUAwEgkWwDAKGaSLQAAViXZAgDG4WxE\nAABWJdkCAMYh2QIAYFWSLQBgHM5GBABgVZItAGAUMzNbAACsSrIFAIxDsgUAwKokWwDAOHZItgAA\nWJFkCwAYx2wamc803iUAwEgkWwDAKGYTmdnSbAEA43C5HgAAViXZAgDGYVFTAABWJdkCAEbhQtQA\nAKxMsgUAjMPZiAAArEqyBQCMw8wWAACrkmwBAOOQbAEAsCrJFgAwipmzEQEAWJVkCwAYh5ktAABW\nJdkCAMaxQ7IFAMCKJFsAwDjMbAEAsCrJFgAwiqmss6XZAgDGMZtGszWNdwkAMBLJFgAwDks/AACw\nKskWADCKmaUfAABYlWQLABiHsxEBAFiVZAsAGIezEQEAWJVkCwAYh7MRAQBYlWQLABjFzMwWAACr\nkmwBAOOwzhYAAKuSbAEA43A2IgAAq5JsAQDjcDYiAACrkmwBAKOY7ZhG5qPZAgDGYekHAABWtWmy\nVVWfS7K+4aHvJtk/yfndfdMhCwMAtjkD8kmSn0xysyT/lOQh3V1JHpjk5KELAwDYDjZttrr7/O4+\nL8mNuvuDi8f+T5LaF8UBANvXbDYb9LZVLDsg/82qem6SDya5XZIvD1cSAMD2seyA/MOTfDPJvTJv\ntB41WEUAwDTMZsPetohlm63zkpyd5KtJ/jnJQYNVBACwjSzbbL0iyY8mOTLzRuu1g1UEAEzDjh3D\n3raIZWe2btTdR1fVHbr7LVX1tEGrAgAYWFXtSHJcklskOT/J0d195obtD0/ypCQ7k7yqu19WVfsn\neU2SGywef2x3n7HZfpZt+/arqoOTrFfVQUnWLuH7AQC4qPFntu6X5IDuPjzJ05K8eLftL0pytyS3\nT/KkqrpGknsm2a+7b5fk95I8f287WbbZelaSU5IckuS0xYsDAFyeHZHkpCTp7tMy73M2+uckV0ty\nQJJZ5gu9/0vmIdSOJFfNfMH3TS11GLG735OkquqaSb7e3et7ew4AwGa2wFpYV838BMBddlbVft19\n4eL+J5J8JMl3kry5u7+5OMJ3gyRnJDk4yS/sbSd7u1zP+3PRy/XsejyL+AwA4PLqnFx0hYUduxqt\nqrp55kte3TDJt5O8rqoenOTwJG/v7qdX1Y8keVdV/fRiEfiLtbdk6yGrvAMAgD0a/4zBU5LcO8mb\nquqwJKdv2HZ2knOTnNvdO6vqq0mukeQ/871Dh9/I/JrRV9hsJ5s2W939f5Okqm6c5MGLF5wluW6S\nYy7hGwIA2EpOTHJkVZ2aeX9zVFU9LMmB3X18Vb0iyclVdUGSf03y6iRXTPKqqnrf4vtndPd3NtvJ\nsks//MWioCOSfCnJgZfiDQEAfM/IM1vdvZbk2N0ePmPD9pcneflu2y9I8ouXZD/L5nff7u4XJPn3\n7n50kmtdkp0AAEzVssnWelVdO8lBVXWVSLYAgFWNP7O1Tyz7Lp+T+cJff57ks0neOVhFAADbyLLJ\n1geSnNPdH1ss4vW2AWsCACZgtmP0dbb2iWWTrdcnudXi+5tkfk0gAIBLb/zL9ewTyzZb1+vuP0uS\n7n5hkusMVxIAwPaxbLO1XlU3SZKqulH2sngXAMBezXYMe9silp3ZemKSv1yckfjFfP+aFAAAXIxl\nL0T9gSxmtqrqR7v7C4NWBQBse1MZkF+q2aqq30ryzSRXz3wp+5O6+zcHrQwAYBtY9oDmAzM/A/Hn\nu/tmSW45XEkAwCQ4G/Eidia5dpL/WNy/8jDlAABsL8sOyL97cXtEVf1hLGoKAKxqC50xOKRlB+Sf\nmeSZSVJVH+7uCxbfH9PdrxiwPgCAy7VL3FLuarQWfukyrAUAmJIds2FvW8Sq+d3WeScAAFvQsjNb\ne7J+mVQBAEzObAudMTikaUymAQCMZNVkaxotKQBw2dtCc1VDWrrZqqq7JrlRktOS/Et3n5fkKUMV\nBgCwHSx7uZ7/keT6SW6a5PwkT0/y0O7+0IC1AQDb2Y5pTDMt+y6P6O5HJfl2d78myQ0HrAkAYNtY\n9jDiflV1QJL1qrpC5pfvAQC49KwgfxF/mOQjSa6Z5ANJXjJYRQAA28iyzdZbkvxjkhsn+VySgwer\nCACYBOtsXdTXkhza3R/q7q8nOW7AmgAAto1lm60zkjyxqh6+uD+NVhQAGM5Ero247GHEbyW5T5I3\nVtW1k3x3uJIAgElwGPEiZt19QZIHJ7l5ksOGKwkAYPtYNtk6Kkm6e2eSX66qtwxXEgAwCZZ+SKrq\nWd39vCQvqKr13Tb/9XBlAQBsD3tLtnYlWG9LcrUkFyZ5apKXDlkUALD9zbbQEPuQNs3vuvvji28f\nm+RTSY5M8owk9x24LgCAbWHZg6VrSd6b5Ord/cbFfQCAS282G/a2RSzbbO2f5IVJ3ltVP5vkisOV\nBACwfVySsxGPTHJC5ocQf3mwigCAadjhbMT/0t2fSfKZxd03DVcOAMD2smyyBQBwmXIhagAAVibZ\nAgDGMZGZrWm8SwCAkUi2AIBxmNkCAGBVki0AYByujQgAwKokWwDAKGazaWQ+03iXAAAjkWwBAOOY\nyNmImi0AYBwG5AEAWJVkCwAYhwF5AABWJdkCAEYxM7MFAMCqJFsAwDgmsvSDZAsAYECSLQBgHJIt\nAABWJdkCAEYx2zGNzGca7xIAYCSSLQBgHJItAABWJdkCAMbhbEQAAFYl2QIAxuHaiAAArEqyBQCM\nYjabRuYzjXcJADASyRYAMI6JnI2o2QIAxmFAHgCAVUm2AIBxTOQwomQLAGBAki0AYBSWfgAAYGWS\nLQBgHM5GBABgVZItAGAcO6aR+UzjXQIAjESyBQCMYmadLQAAViXZAgDGMfLMVlXtSHJcklskOT/J\n0d195obtD0/ypCQ7k7yqu1+2t+dcHMkWADBV90tyQHcfnuRpSV682/YXJblbktsneVJVXWOJ53wf\nzRYAMI7ZbNjb3h2R5KQk6e7Tkhyy2/Z/TnK1JAckmSVZX+I530ezBQBM1VWTnL3h/s6q2jhi9Ykk\nH0nyySRv7e5vLvGc76PZAgDGMX6ydU6Sgzbc39HdFyZJVd08yb2S3DDJDZL8cFU9eLPn7IlmCwCY\nqlOS3DNJquqwJKdv2HZ2knOTnNvdO5N8Nck19vKci+VsRABgFLPxr414YpIjq+rUzGeyjqqqhyU5\nsLuPr6pXJDm5qi5I8q9JXp3kwt2fs7edaLYAgEnq7rUkx+728Bkbtr88ycsv5qm7P2dTmi0AYByz\naUwzabYAgHG4XA8AAKuSbAEA4xh/QH6fkGwBAAxIsgUAjGI2kQH5abxLAICRSLYAgHGY2QIAYFWS\nLQBgFOcecKVBX/+gvf/IPiHZAgAYkGYLAGBAmi0AgAFptgAABqTZAgAYkGYLAGBAmi0AgAFptgAA\nBqTZAgAY0KAryD/2bvce8uWBfeyV//iWsUsALmvP/rWxK9j2JFsAAAPSbAEADEizBQAwIM0WAMCA\nNFsAAAPSbAEADEizBQAwIM0WAMCABl3UFABgT757hf3HLmGfkGwBAAxIsgUAjGJ9fewK9g3JFgDA\ngCRbAMAo1iYSbUm2AAAGJNkCAEaxLtkCAGBVki0AYBSSLQAAVibZAgBG4WxEAABWJtkCAEYxkWBL\nsgUAMCTJFgAwCmcjAgCwMskWADCKtUwj2dJsAQCjcBgRAICVSbYAgFFY1BQAgJVJtgCAUaytSbYA\nAFiRZAsAGMVERrYkWwAAQ5JsAQCjsM4WAAArk2wBAKOYyuV6JFsAAAOSbAEAozCzBQDAyiRbAMAo\nJFsAAKxMsgUAjGIil0aUbAEADEmyBQCMwswWAAArk2wBAKOYSrKl2QIARrE2kWbLYUQAgAFJtgCA\nUUi2AABYmWQLABjFVAbkJVsAAAOSbAEAozCzBQDAyiRbAMAoJhJsSbYAAIYk2QIARuFsRAAAVibZ\nAgBG4WxEAABWJtkCAEYx9sxWVe1IclySWyQ5P8nR3X3mYtu1k7xxw4/fMsnTkpyQ5FVJbpDkSkme\n191/t9l+JFsAwFTdL8kB3X145o3Ui3dt6O6vdPedu/vOSZ6e5KNJXpnkEUnO6u47JLlHkj/d2040\nWwDAKNbXh70t4YgkJyVJd5+W5JDdf6CqZkn+JMnju3tnkr9K8tuLzbMkF+5tJw4jAgBTddUkZ2+4\nv7Oq9uvujQ3UvZN8srs7Sbr720lSVQcl+eskz9rbTjRbAMAotsDZiOckOWjD/R27NVrJ/LDhH298\noKp+JMmJSY7r7r/Y204cRgQApuqUJPdMkqo6LMnpF/MzhyQ5ddedqrpWknckeWp3v2qZnUi2AIBR\njH02Yubp1JFVdWrm81dHVdXDkhzY3cdX1TWTnNPdGwt9RpJrJPntqto1u/Xz3X3unnai2QIARjH2\nYcTuXkty7G4Pn7Fh+9cyX/Jh43OekOQJl2Q/DiMCAAxIsgUAjGLsZGtfkWwBAAxIsgUAjGILDMjv\nE5ItAIABSbYAgFFItgAAWJlkCwAYxdo0gi3JFgDAkCRbAMAozGwBALAyyRYAMArJFgAAK5NsAQCj\nWItkCwCAFUm2AIBRmNkCAGBlki0AYBRWkAcAYGWSLQBgFGsTibY0WwDAKAzIAwCwMskWADAKyRYA\nACuTbAEAo3C5HgAAVibZAgBGYWYLAICVSbYAgFFMJNiSbAEADEmyBQCMYm0i0ZZkCwBgQJItAGAU\nzkYEAGBlki0AYBSSLQAAVibZAgBG4WxEAABWJtkCAEYh2QIAYGWSLQBgFM5GBABgZZItAGAUa9MI\ntjRbAMA4HEYEAGBlki0AYBSSLQAAVibZAgBGYVFTAABWJtkCAEYxkWBLsgUAMCTJFgAwiqmcjbjH\nZquqfnRP27r7C8OUAwCwvWyWbP3l4usPJTkoySeS3CzJfyS59cB1AQDb3OTPRuzuw7v78CSfTHKT\n7j4yyU2S/Pu+Kg4A4PJumQH563f3t5Kku7+T5DrDlgQATMH6+vqgt61imQH5d1TVe5J8OMmhSf52\n2JIAALaPvTZb3f3MqrpNkp9I8tru/vjwZQEA293kZ7Z2qarrJXliksckObSqbjt4VQAA28QyM1vH\nJ3lVkv2TvDfJHw9aEQAwCWvr64Petoplmq0f6O53JVnv7k5y3sA1AQBsG8sMyJ9XVXdPcoWqOiya\nLQDgMrCVzhgc0jLJ1uOSHJXk4CRPTvL4QSsCANhGNrtczxUX3341yaP2TTkAwFRMJNja9DBiJ1lP\nMlt8zYbvf3zgugCAbW4rDbEPaY/NVnffcF8WAgCwHe11QL6q7pPkVzNf+mGW5Ie6++ZDFwYAbG8G\n5L/neUmeneTfkrwmyelDFgQAsJ0s02x9ubvfnyTd/eok1xu0IgBgEqZyIeplmq3zq+qOSfZfrLd1\n8MA1AQBsG8ssavr4JJX54cTnLr4CAKxkKmcjLpNsHZDkWt39qSSfSXLasCUBAGwfyzRbr03yucX3\nb0tywnDlAABTsT7wbatYptlKd5+2+Pq+ZZ8DAMByM1vfrKrHJXl/kkOTfGvYkgCAKTCz9T2/nORm\nSV64+PqYQSsCANhG9ppsdffXq+p3k6wluV+SnYNXBQBse1tpLawhLXO5njcmeWuS22WehD0gyf0H\nrgsAYFtY5jDidbv7dUlu2t3HJjlo4JoAgAlYW1sf9LZVLNNsXbGqHpDkU1V1cDRbAABLW+ZsxBcm\n+aUkT0ryG5mvIg8AsJKxZ7aqakeS45LcIsn5SY7u7jM3bP+ZJC9JMkvylSSP6O7zFtt+OMlHkhzZ\n3Wdstp9lBuTfnOTNi7u/s6GAl3X34y/JmwIA2ELul+SA7j68qg5L8uIk902SqpoleWWSB3X3mVV1\ndJIfS9JVtX+SVyQ5d5mdrLJAaa3wXABg4tbW1we9LeGIJCcl/7WA+yEbtt0kyVlJnlhV70nyg93d\ni20vSvLyJF9aZidWgwcApuqqSc7ecH9nVe066ndw5isx/GmSuyW5a1XdpaoeneRr3f32ZXei2QIA\nRrEFro14Ti564t+O7r5w8f1ZSc7s7k9393czT8AOyXxx9yOr6t1JbpnktVV17c12otkCAEaxvr4+\n6G0JpyS5Z5IsZrZO37Dts0kOrKobL+7fIcknu/uO3X2n7r5zko8leVR3f2WznSxzNuKezFZ4LgDA\n2E7MPKU6NfO+5qiqeliSA7v7+Kr6lSR/sRiWP7W733ZpdrLHZmtx8emL1d3HJ/m5S7NDAIBk/AtR\nd/dakmN3e/iMDdvfleTQTZ5/52X2s1mydZ09PL6+2MF3l9kBAMCUbdZsvWGfVQEATM7Yi5ruK5s1\nW6/IPMXafTZrPcldBqsIAGAb2WOz1d0/uy8LAQCmZeyZrX1lswH5v+7uB1XVl/O95SpmSda7+7r7\npDoAgMu5zZKtBy2+7mlQHgDgUptIsLX3dbaq6pDM57euleQLSR7X3Z8YujAAgO1gmRXkX5rkkd19\n/STHJHnZsCUBAFOwBVaQ3yeWabbO7e5PJUl3n57kgmFLAgDYPpZZQf67VXVckvdmvorqOfuiMABg\ne5v82Yj53gry7198rSRnZ37RRQAAlrDZ2YjP2eyJVXVid9//si8JAJiCqSRby8xs7cnVL7MqAAC2\nqb0u/bCJabSjAMAgttIZg0NaJdkCAGAvVkm2AAAuNcnW3v3nZVYFAMA2tdk6Wy/IHuayuvsZ3f3A\nwaoCALa9tWkEW5seRjxjn1UBAEzOVA4jbrbO1muSpKr2S/IzSfZPMkty3X1TGgDA5d8yA/InZt5o\nXS/JFZJ8KckbhiwKANj+ppJsLTMgf3B33yPJB5LcJskBw5YEALB9LNNs/b/F16t097mxmCkAcBlY\nW18f9LZVLNNsvbmqfjvJx6vqtCTnD1wTAMC2sczM1v9K8sXuXq+qtyW5cOCaAIAJmMrM1mbrbP23\nzIfi/yDJU6oqmQ/IvyDJLfdJdQAAl3ObJVvXSPKQJNdK8tDFY2tJjhu6KABg+5v8oqbd/b4k76uq\nW3f3R6vqmknO6u61fVceAMDl2zID8lerqs8meUeSz1bVkQPXBABMwNr62qC3rWKZZuu5SY7o7lsl\nuX2S5w1bEgDA9rFMs7Wzu7+UJN39xSTnDVsSADAF6+vD3raKZZZ+OKeqfj3Je5PcMclZw5YEALB9\nLNNsfTDJj2R++PDTSb42aEUAwCRYZ6vqV5IcneSmmTdZSXKnzC9KDQDAEjZLtl6X5J1JnpHk+YvH\n1pJ8deiiAIDtbytdv3BIm62zdX6Szyd53D6rBgBgm1lmZgsA4DI3lZmtZZZ+AADgUpJsAQCjkGwB\nALAyyRYAMIq1aQRbmi0AYBwOIwIAsDLJFgAwirVItgAAWJFkCwAYhZktAABWJtkCAEaxNpG1HyRb\nAAADkmwBAKMwswUAwMokWwDAKCYysiXZAgAYkmQLABiFmS0AAFYm2QIARrHu2ogAAKxKsgUAjGLN\nzBYAAKuSbAEAo3A2IgAAK5NsAQCjmMoK8potAGAUDiMCALAyyRYAMArJFgAAK5NsAQCjsKgpAAAr\nk2wBAKOQbAEAsDLJFgAwCmcjAgCwMskWADCKiQRbki0AgCFJtgCAUTgbEQCAlUm2AIBROBsRAICV\nSbYAgFGY2QIAYGWSLQBgFFOZ2dJsAQCTVFU7khyX5BZJzk9ydHefuWH7E5McneRri4eO6e6uqqcn\nuU+SKyY5rrtP2Gw/mi0AYBRbINi6X5IDuvvwqjosyYuT3HfD9tskeVR3f2TXA1V15yS3S3L7JFdO\n8uS97cTMFgAwirX19UFvSzgiyUlJ0t2nJTlkt+23SfL0qjp5kWYlyd2TnJ7kxCRvSfLWve1EswUA\nTNVVk5y94f7Oqtp41O+NSY5NcpckR1TVLyQ5OPOm7MGLba+vqtlmO3EYEQAYxRYYkD8nyUEb7u/o\n7guTZNFA/VF3n724/7Ykt0pyVpIzuvuCJF1V5yW5ZpKv7mknki0AYKpOSXLPJFnMbJ2+YdtVk3yi\nqg5cNF53SfKRJCcnuUdVzarqukmuknkDtkezLdBVAgDscxvORrx5klmSo5LcOsmB3X18VT0yyW9k\nfqbiO7v7dxfPe2GSn808tHpGd799s/1otgAABuQwIgDAgDRbAAAD0mwBAAxIswUAMCDNFgDAgDRb\nE1NVt6yq39kCddygqk5b8mcPqKrPD1sRjG/x3/rRm2y/Y1XdfJPtj66q399k+7Or6tiLefzNi6/v\nrqqf3NPPXVaq6vNVdcCSP3taVd1gqFpgX9BsTUx3f6y7f2/sOoCLde0ke2y2kjwmyXUv65129wMu\n69cEvsflera5qrpJkj9LcmHmzfXxSe6V5OmLx5PkwCQ3zfxyA/dK8ptJdiY5ubuftslrPz/zRd32\nS/I33f0HVXXbJH+02NcXkzw8yaFJfnfx2IFJHpbkgg2vc6ckz1/s81+THJPkSklen+QaSc5c8Z8B\nLi+emeRmi/T50MxXsN4vybMyv37bPZLcuqo+leQ+SR6Q+erVX09y/yX3cf+q+sUkV07yG939war6\nSndfe9kiq+oBSZ6a5LtJvpTkIUl+KMlrklw988UhH5Xk3CQvS3JAkuskeVZ3/+2G1/mRzP8m/cDi\nZx/X3f+2+NtyjyT/lvl16OByTbK1/R2Z5INJ7pZ5w3O1JOnuz3X3nTO/evk3Mr+g5gFJnpPkrt19\nRJLrVdWRm7z2wzNvnO6Q5JuLx16R5DHdfdskb8u8ifupJI9Y7O/Ni30l+a9rT70yyQO6+06ZN2iP\nzvzinp/o7jsuXhOm4PlJPpV5k/UPi//+H5zkhCQfTXJSkqck+ffMm5u7LX7X9kvyM0vu43PdfZck\nv5Lk5Zeyzocm+Z+LvxNvXdT7rCR/1923S/KkzJvFn0zy4u4+Msnjkvzqbq/zoiQvXfxteFGS36+q\nQ5LccfF+HpWLXrcOLpc0W9vfCZk3Qicl+bXME64kyeLK5m9M8rru/vskN8483fr7qnp3kpsludEm\nr/3wJL+f5O2Zf5pNkmt396eTpLtP6O6PZt5AvbSqXp15Erb/hte4ZuafeN+02OfPJfmxJDfJvElM\nd38g80/QMBU3TfLeJOnuL2Z+sdwf3rWxu9cyT4ffUFUnJLl+Lvp7tZldr/vJzA9bXhq/meQuVfWe\nJLdLspakkrx/8dqndvfrk3w5yTFV9eeZf4DavcafTvKMxe/+7yS5Vua/+x/u7rXuPicXvVYdXC5p\ntra/+yZ5X3ffNclfZR7970qUTkhyane/dvGzn8s8tj9y8UnzT5Jc7BB7VV0p80/cD828gXp0Vf1Y\nki9V1U8sfuapVXX/zJOro7r70ZkfcphteKmvZ/4p/b6LfT4/ybsy/3R/+OJ1bpXl/0cCl2drmf9d\n/nTmiXGq6nqZH04/a9f2xZD8/br7l5L8+uI5s4t9xe936OJ1fzrJFy5lnY9L8uxFGj3L/BDmp7NI\n1xaD/H+Q5LlJXtvdj0zyTxdT4xlJnrr43T8m879Rn0pyaFXtqKqrZP6hDy7XzGxtfx9O8pqqelaS\nK2TeQB2a5EFJHpj5ocJ7LX72vyd5SZL3VNUVknw+yZsu7kW7+/yq+kbmzdi5Sd6R+R/uY5K8qqrW\nMv9U+0dJXpfkfVX1nST/kQ0Dvt29VlVPSPK2xQVBz8n80MGpSV5bVSdn/gf5/MvmnwO2tK8muWLm\nh/vvUlUPynye6XHdfWFVfSDzNPmhSb5TVacsnvflLD84f8Oqelfmc5HHXMo6P5jkrVX1rSTfzvxQ\n4t9n/run3yD/AAAAk0lEQVT/iCTrmR+mvG2SF1XV0zP/ULX7/NWTk7xscWbiDyR5Qnd/rKr+d5IP\nZf7h7KuXskbYMlyIGgBgQJItNlVVhyZ54cVs+svuftm+rgfYu8W6WT+428Nnd/d9L8FrXDHzxHp3\n3d2XNhGDSZJsAQAMyIA8AMCANFsAAAPSbAEADEizBQAwIM0WAMCANFsAAAP6/5RnpJwG384dAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e82ddd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define a function that will take the sparse vector corresponding to the \"features\" column\n",
    "#and break it up into separate columns. then grab the last two columns and return those\n",
    "def dosplit(row):\n",
    "    return row[0].toArray().tolist()[-2:]\n",
    "\n",
    "#grab the \"features\" column and split it into a dataframe of separate columns. to do this,\n",
    "#first use an RRD mapping function. then convert the returned RDD result back into a dataframe.\n",
    "#this DF-->RDD-->DF process is required since we are returning more than one column, which a UDF\n",
    "#is not able to do\n",
    "cont_feats = output.select('features')\n",
    "cont_feats = cont_feats.rdd.map(dosplit).toDF(['size_scaled', 'total_bill_scaled'])\n",
    "print 'preview of continuous features DF:'\n",
    "cont_feats.limit(3).toPandas()\n",
    "\n",
    "#compute the correlation matrix\n",
    "cont_feats = cont_feats.toPandas()\n",
    "corr = cont_feats.corr()\n",
    "print 'correlation matrix:'\n",
    "corr\n",
    "\n",
    "#plot the correlation matrix as a heatmap \n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, cmap=cmap, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, total bill and size are somewhat correlated. But the correlation isn't incredibly high, and we don't have many continuous features to work with, so let's keep both features for now.  \n",
    "\n",
    "Now, it's time to develop a linear regression model. There are two paramters that will need to be determined via cross validation: elasticNetParam (determines the weight of the L1 vs L2 penalty) and regParam (the regularization parameter). So we'll leave those undefined for now. Furthermore, our pipeline output already matches the default input column name and features column name, so we don't have to specify those. We define standardization to be false, since we took care of that ourselves with the StandardScaler. Lastly, limit the number of iterations of SGD to 15 just to keep things from taking too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(standardization=False, maxIter=15)\n",
    "\n",
    "#chain everything together into a pipeline\n",
    "pipeline = Pipeline(stages=[stringIndexerSex, stringIndexerSmoker, stringIndexerDay, encoderDay, \\\n",
    "                            stringIndexerTime, assemblerScaler, scaler, assemblerAllFeatures, model])\n",
    "\n",
    "#define a ParamGridBuilder to determine optimal values of elasticNetParam (range [0,1]) and regParam (typically \n",
    "#ranges between 0 and 1). we'll sweep through 0 to 1 in increments of 0.1 for both parameters\n",
    "paramGrid = ParamGridBuilder().addGrid(model.elasticNetParam, np.array(range(0,11))/10.) \\\n",
    "                              .addGrid(model.regParam, np.array(range(0,11))/10.).build()\n",
    "\n",
    "#define the RMSE to be the evaluation metric for model performance\n",
    "evaluator = RegressionEvaluator(metricName='rmse')\n",
    "\n",
    "#set up 3-fold cross validation to determine the optimal depth parameter (this can be set higher for potentially \n",
    "#better results)\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "#do the actual cross validation on the training data\n",
    "CV_model = crossval.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CrossValidator iterated through every possible combination of elasticNetParam and regParam, developed a model for each combination of values, and evaluated each model's performance based on the RMSE. The best performing model was saved and can now be accessed from the CV_model object. Let's take a closer look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['sex', 'smoker', 'day_1', 'day_2', 'day_3', 'time', 'size', 'total_bill']\n",
      "feature weights: [0.0,0.103632849468,-0.0778953142103,0.0,0.0,0.0,0.20978543848,0.611321703809]\n",
      "numIterations: 10\n",
      "RMSE: 0.962601\n",
      "r2: 0.439849\n"
     ]
    }
   ],
   "source": [
    "#get the pipeine corresponding to the best model\n",
    "best_model = CV_model.bestModel\n",
    "\n",
    "#grab the last stage of the pipeline (the model)\n",
    "print ('features: %s') % (['sex', 'smoker', 'day_1', 'day_2', 'day_3', 'time', 'size', 'total_bill'])\n",
    "print ('feature weights: %s') % (best_model.stages[-1].coefficients)\n",
    "trainingSummary = best_model.stages[-1].summary\n",
    "\n",
    "#print out some of the model's properties\n",
    "print ('numIterations: %d') % (trainingSummary.totalIterations)\n",
    "print('RMSE: %f') % (trainingSummary.rootMeanSquaredError)\n",
    "print('r2: %f') % (trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training converged after 10 iterations. Each of the eight features and their corresponding weights is listed above. Surprisingly, no weight was given to most of the categorical features. However, the total bill feature was highly weighted, which is an intuitive result.  \n",
    "\n",
    "To understand if these results are reasonable, I ran the same linear regression analysis in scikit learn with 5 fold cross validation. Here are the results I obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn features: ['sex', 'smoker', 'day_1', 'day_2', 'day_3', 'time', 'size', 'total_bill']\n",
      "sklearn feature weights: [0.04448793, -0.29463104, 0.09389824, 0.14555511, -0.21086302, 0.31639053, 0.11035866, 0.90419216]\n",
      "sklearn RMSE: 1.063000\n",
      "sklearn r2: 0.358000\n"
     ]
    }
   ],
   "source": [
    "sklearn_coeffs = [0.04448793, -0.29463104, 0.09389824, 0.14555511, -0.21086302, 0.31639053, 0.11035866, 0.90419216]\n",
    "sklearn_feats = ['sex', 'smoker', 'day_1', 'day_2', 'day_3', 'time', 'size', 'total_bill']\n",
    "sklearn_RMSE = 1.063\n",
    "sklearn_R2 = 0.358\n",
    "\n",
    "print ('sklearn features: %s') % (sklearn_feats)\n",
    "print ('sklearn feature weights: %s') % (sklearn_coeffs)\n",
    "print('sklearn RMSE: %f') % (sklearn_RMSE)\n",
    "print('sklearn r2: %f') % (sklearn_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While scikit did put nonzero weights on all the categorical features, it's clear that total bill is still heavily weighted in comparison to the remaining features. Furthermore, scikit's RMSE is almost identical, and the r2 is actually worse. So it seems that Spark's results are actually better.  \n",
    "\n",
    "Either way, the r2 value is low in both cases and indicates that linear regression may not be the best model to fit this data. To find out what the best model might be, it would be necessary to do some data visualization (for example, plotting each input feature versus the tip). Let's just continue working with this model as it is.  \n",
    "\n",
    "Now that we have a model, let's try applying it to our validation data to make sure it's behavior is consistent. We can directly apply our cross validation model to the validation data to obtain predictions (recall that it has saved the best model pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>label</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>sex_numeric</th>\n",
       "      <th>smoker_numeric</th>\n",
       "      <th>day_numeric</th>\n",
       "      <th>day_vector</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>cont_feats</th>\n",
       "      <th>cont_feats_scaled</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.35</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2.0, 8.35]</td>\n",
       "      <td>[-0.54207712072, -1.26397658203]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 1.0, -0.54207712072,...</td>\n",
       "      <td>1.987965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.59</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 11.59]</td>\n",
       "      <td>[-0.54207712072, -0.88163555739]</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...</td>\n",
       "      <td>2.247436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.61</td>\n",
       "      <td>3.39</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 11.61]</td>\n",
       "      <td>[-0.54207712072, -0.879275427608]</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...</td>\n",
       "      <td>2.145246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  label     sex smoker   day    time  size  sex_numeric  \\\n",
       "0        8.35   1.50  Female     No  Thur   Lunch   2.0          1.0   \n",
       "1       11.59   1.50    Male    Yes   Sat  Dinner   2.0          0.0   \n",
       "2       11.61   3.39    Male     No   Sat  Dinner   2.0          0.0   \n",
       "\n",
       "   smoker_numeric  day_numeric       day_vector  time_numeric    cont_feats  \\\n",
       "0             0.0          2.0  (0.0, 0.0, 1.0)           1.0   [2.0, 8.35]   \n",
       "1             1.0          0.0  (1.0, 0.0, 0.0)           0.0  [2.0, 11.59]   \n",
       "2             0.0          0.0  (1.0, 0.0, 0.0)           0.0  [2.0, 11.61]   \n",
       "\n",
       "                   cont_feats_scaled  \\\n",
       "0   [-0.54207712072, -1.26397658203]   \n",
       "1   [-0.54207712072, -0.88163555739]   \n",
       "2  [-0.54207712072, -0.879275427608]   \n",
       "\n",
       "                                            features  prediction  \n",
       "0  [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, -0.54207712072,...    1.987965  \n",
       "1  (0.0, 1.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...    2.247436  \n",
       "2  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...    2.145246  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse for validation data: 1.235193\n"
     ]
    }
   ],
   "source": [
    "data_val_transformed = CV_model.transform(data_val)\n",
    "data_val_transformed.limit(3).toPandas()\n",
    "\n",
    "#now use the evaluator to determine the RMSE on the validation data \n",
    "print ('%s for validation data: %f') % (evaluator.getMetricName(), evaluator.evaluate(data_val_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The results are fairly consistent with the training data, so this is good news. Whenver we get new data that we want to evaluate, we can now simply apply the CV_model to it and get the results. You can save the best model here and load it at any later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#note that the below save function creates a folder called \"best_model_tip\". if you call \"save\" again, you need\n",
    "#to first delete that folder.\n",
    "best_model.save('best_model_tip')\n",
    "loaded_best_model = PipelineModel.load('best_model_tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that we get the same results from applying the loaded model to the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>label</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>sex_numeric</th>\n",
       "      <th>smoker_numeric</th>\n",
       "      <th>day_numeric</th>\n",
       "      <th>day_vector</th>\n",
       "      <th>time_numeric</th>\n",
       "      <th>cont_feats</th>\n",
       "      <th>cont_feats_scaled</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.35</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0, 0.0, 1.0)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[2.0, 8.35]</td>\n",
       "      <td>[-0.54207712072, -1.26397658203]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0, 1.0, -0.54207712072,...</td>\n",
       "      <td>1.987965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.59</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 11.59]</td>\n",
       "      <td>[-0.54207712072, -0.88163555739]</td>\n",
       "      <td>(0.0, 1.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...</td>\n",
       "      <td>2.247436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.61</td>\n",
       "      <td>3.39</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.0, 11.61]</td>\n",
       "      <td>[-0.54207712072, -0.879275427608]</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...</td>\n",
       "      <td>2.145246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  label     sex smoker   day    time  size  sex_numeric  \\\n",
       "0        8.35   1.50  Female     No  Thur   Lunch   2.0          1.0   \n",
       "1       11.59   1.50    Male    Yes   Sat  Dinner   2.0          0.0   \n",
       "2       11.61   3.39    Male     No   Sat  Dinner   2.0          0.0   \n",
       "\n",
       "   smoker_numeric  day_numeric       day_vector  time_numeric    cont_feats  \\\n",
       "0             0.0          2.0  (0.0, 0.0, 1.0)           1.0   [2.0, 8.35]   \n",
       "1             1.0          0.0  (1.0, 0.0, 0.0)           0.0  [2.0, 11.59]   \n",
       "2             0.0          0.0  (1.0, 0.0, 0.0)           0.0  [2.0, 11.61]   \n",
       "\n",
       "                   cont_feats_scaled  \\\n",
       "0   [-0.54207712072, -1.26397658203]   \n",
       "1   [-0.54207712072, -0.88163555739]   \n",
       "2  [-0.54207712072, -0.879275427608]   \n",
       "\n",
       "                                            features  prediction  \n",
       "0  [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, -0.54207712072,...    1.987965  \n",
       "1  (0.0, 1.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...    2.247436  \n",
       "2  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, -0.54207712072,...    2.145246  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val_transformed_loaded = loaded_best_model.transform(data_val)\n",
    "data_val_transformed_loaded.limit(3).toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
